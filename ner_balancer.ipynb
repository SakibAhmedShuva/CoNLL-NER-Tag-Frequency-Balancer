{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Tag Frequency Balancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Set\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERBalancer:\n",
    "    def __init__(self, target_frequencies: Dict[str, int], max_iterations: int = 50):\n",
    "        self.target_frequencies = target_frequencies\n",
    "        self.max_iterations = max_iterations\n",
    "        \n",
    "    def read_conll(self, filename: str) -> List[List[Tuple[str, str]]]:\n",
    "        \"\"\"Read CoNLL file and return list of sentences with (word, tag) pairs.\"\"\"\n",
    "        sentences = []\n",
    "        current_sentence = []\n",
    "        \n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line.startswith('-DOCSTART-') or not line:\n",
    "                    if current_sentence:\n",
    "                        sentences.append(current_sentence)\n",
    "                        current_sentence = []\n",
    "                    continue\n",
    "                    \n",
    "                parts = line.split()\n",
    "                word = parts[0]\n",
    "                tag = parts[-1]\n",
    "                current_sentence.append((word, tag))\n",
    "                \n",
    "            if current_sentence:\n",
    "                sentences.append(current_sentence)\n",
    "                \n",
    "        return sentences\n",
    "\n",
    "    def get_sentence_tag_counts(self, sentence: List[Tuple[str, str]]) -> Dict[str, int]:\n",
    "        \"\"\"Count occurrences of each tag in a sentence.\"\"\"\n",
    "        counts = defaultdict(int)\n",
    "        for _, tag in sentence:\n",
    "            if tag != 'O':\n",
    "                counts[tag] += 1\n",
    "        return counts\n",
    "\n",
    "    def get_current_counts(self, sentences: List[List[Tuple[str, str]]], selected: Set[int], \n",
    "                          sentence_tag_counts: List[Dict[str, int]]) -> Dict[str, int]:\n",
    "        \"\"\"Get current tag counts from selected sentences.\"\"\"\n",
    "        counts = defaultdict(int)\n",
    "        for idx in selected:\n",
    "            for tag, count in sentence_tag_counts[idx].items():\n",
    "                counts[tag] += count\n",
    "        return counts\n",
    "\n",
    "    def calculate_frequency_score(self, current_counts: Dict[str, int]) -> float:\n",
    "        \"\"\"Calculate how far current frequencies are from targets.\"\"\"\n",
    "        score = 0\n",
    "        for tag, target in self.target_frequencies.items():\n",
    "            current = current_counts.get(tag, 0)\n",
    "            score -= abs(current - target)\n",
    "        return score\n",
    "\n",
    "    def should_remove_sentence(self, idx: int, sentence_counts: Dict[str, int], \n",
    "                             current_counts: Dict[str, int]) -> bool:\n",
    "        \"\"\"Determine if removing a sentence would improve overall balance.\"\"\"\n",
    "        for tag, count in sentence_counts.items():\n",
    "            if tag in self.target_frequencies:\n",
    "                current = current_counts[tag]\n",
    "                target = self.target_frequencies[tag]\n",
    "                if current < target:\n",
    "                    # Don't remove if we're already under target\n",
    "                    return False\n",
    "                if current - count < target * 0.8:  # Allow some undershoot\n",
    "                    # Don't remove if it would put us too far under target\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    def balance_dataset(self, sentences: List[List[Tuple[str, str]]]) -> List[List[Tuple[str, str]]]:\n",
    "        \"\"\"Balance the dataset through iterative refinement.\"\"\"\n",
    "        sentence_tag_counts = [self.get_sentence_tag_counts(sent) for sent in sentences]\n",
    "        best_selected = set()\n",
    "        best_score = float('-inf')\n",
    "        \n",
    "        # Initial selection\n",
    "        selected = set(range(len(sentences)))\n",
    "        current_counts = self.get_current_counts(sentences, selected, sentence_tag_counts)\n",
    "        \n",
    "        for iteration in range(self.max_iterations):\n",
    "            improved = False\n",
    "            \n",
    "            # Try removing sentences that contribute to over-represented tags\n",
    "            for idx in list(selected):\n",
    "                sentence_counts = sentence_tag_counts[idx]\n",
    "                if self.should_remove_sentence(idx, sentence_counts, current_counts):\n",
    "                    selected.remove(idx)\n",
    "                    for tag, count in sentence_counts.items():\n",
    "                        current_counts[tag] -= count\n",
    "                    improved = True\n",
    "            \n",
    "            # Try adding sentences that help under-represented tags\n",
    "            available = set(range(len(sentences))) - selected\n",
    "            for idx in list(available):\n",
    "                sentence_counts = sentence_tag_counts[idx]\n",
    "                can_add = True\n",
    "                for tag, count in sentence_counts.items():\n",
    "                    if tag in self.target_frequencies:\n",
    "                        if current_counts[tag] + count > self.target_frequencies[tag] * 1.1:  # Allow 10% overshoot\n",
    "                            can_add = False\n",
    "                            break\n",
    "                \n",
    "                if can_add:\n",
    "                    selected.add(idx)\n",
    "                    for tag, count in sentence_counts.items():\n",
    "                        current_counts[tag] += count\n",
    "                    improved = True\n",
    "            \n",
    "            # Calculate score for this iteration\n",
    "            score = self.calculate_frequency_score(current_counts)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_selected = selected.copy()\n",
    "            \n",
    "            if not improved:\n",
    "                break\n",
    "            \n",
    "            # Print progress every 10 iterations\n",
    "            if iteration % 10 == 0:\n",
    "                print(f\"Iteration {iteration}, current score: {score}\")\n",
    "                self.print_current_stats(current_counts)\n",
    "        \n",
    "        # Return best result found\n",
    "        return [sentences[idx] for idx in sorted(best_selected)]\n",
    "\n",
    "    def write_conll(self, sentences: List[List[Tuple[str, str]]], output_filename: str):\n",
    "        \"\"\"Write sentences back to CoNLL format.\"\"\"\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write('-DOCSTART- -X- O O\\n\\n')\n",
    "            for sentence in sentences:\n",
    "                for word, tag in sentence:\n",
    "                    f.write(f\"{word} -X- _ {tag}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "    def print_current_stats(self, current_counts: Dict[str, int]):\n",
    "        \"\"\"Print current tag frequencies and differences from targets.\"\"\"\n",
    "        print(\"\\nCurrent tag frequencies:\")\n",
    "        for tag, count in sorted(current_counts.items()):\n",
    "            target = self.target_frequencies.get(tag, 0)\n",
    "            diff = count - target if target > 0 else count\n",
    "            print(f\"{tag}: {count} (target: {target}, diff: {diff})\")\n",
    "\n",
    "    def process_file(self, input_filename: str, output_filename: str):\n",
    "        \"\"\"Process the entire file.\"\"\"\n",
    "        sentences = self.read_conll(input_filename)\n",
    "        balanced_sentences = self.balance_dataset(sentences)\n",
    "        self.write_conll(balanced_sentences, output_filename)\n",
    "        \n",
    "        # Print final statistics\n",
    "        tag_counts = defaultdict(int)\n",
    "        for sentence in balanced_sentences:\n",
    "            for _, tag in sentence:\n",
    "                if tag != 'O':\n",
    "                    tag_counts[tag] += 1\n",
    "                    \n",
    "        print(\"\\nFinal tag frequencies:\")\n",
    "        for tag, count in sorted(tag_counts.items()):\n",
    "            target = self.target_frequencies.get(tag, 0)\n",
    "            diff = count - target if target > 0 else count\n",
    "            print(f\"{tag}: {count} (target: {target}, diff: {diff})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, current score: -555\n",
      "\n",
      "Current tag frequencies:\n",
      "B-LOC: 480 (target: 350, diff: 130)\n",
      "B-MISC: 385 (target: 350, diff: 35)\n",
      "B-ORG: 456 (target: 350, diff: 106)\n",
      "B-PER: 385 (target: 350, diff: 35)\n",
      "I-LOC: 345 (target: 350, diff: -5)\n",
      "I-MISC: 539 (target: 350, diff: 189)\n",
      "I-ORG: 376 (target: 350, diff: 26)\n",
      "I-PER: 379 (target: 350, diff: 29)\n",
      "Iteration 10, current score: -530\n",
      "\n",
      "Current tag frequencies:\n",
      "B-LOC: 479 (target: 350, diff: 129)\n",
      "B-MISC: 385 (target: 350, diff: 35)\n",
      "B-ORG: 445 (target: 350, diff: 95)\n",
      "B-PER: 385 (target: 350, diff: 35)\n",
      "I-LOC: 345 (target: 350, diff: -5)\n",
      "I-MISC: 530 (target: 350, diff: 180)\n",
      "I-ORG: 376 (target: 350, diff: 26)\n",
      "I-PER: 375 (target: 350, diff: 25)\n",
      "Iteration 20, current score: -530\n",
      "\n",
      "Current tag frequencies:\n",
      "B-LOC: 479 (target: 350, diff: 129)\n",
      "B-MISC: 385 (target: 350, diff: 35)\n",
      "B-ORG: 445 (target: 350, diff: 95)\n",
      "B-PER: 385 (target: 350, diff: 35)\n",
      "I-LOC: 345 (target: 350, diff: -5)\n",
      "I-MISC: 530 (target: 350, diff: 180)\n",
      "I-ORG: 376 (target: 350, diff: 26)\n",
      "I-PER: 375 (target: 350, diff: 25)\n",
      "Iteration 30, current score: -530\n",
      "\n",
      "Current tag frequencies:\n",
      "B-LOC: 479 (target: 350, diff: 129)\n",
      "B-MISC: 385 (target: 350, diff: 35)\n",
      "B-ORG: 445 (target: 350, diff: 95)\n",
      "B-PER: 385 (target: 350, diff: 35)\n",
      "I-LOC: 345 (target: 350, diff: -5)\n",
      "I-MISC: 530 (target: 350, diff: 180)\n",
      "I-ORG: 376 (target: 350, diff: 26)\n",
      "I-PER: 375 (target: 350, diff: 25)\n",
      "Iteration 40, current score: -530\n",
      "\n",
      "Current tag frequencies:\n",
      "B-LOC: 479 (target: 350, diff: 129)\n",
      "B-MISC: 385 (target: 350, diff: 35)\n",
      "B-ORG: 445 (target: 350, diff: 95)\n",
      "B-PER: 385 (target: 350, diff: 35)\n",
      "I-LOC: 345 (target: 350, diff: -5)\n",
      "I-MISC: 530 (target: 350, diff: 180)\n",
      "I-ORG: 376 (target: 350, diff: 26)\n",
      "I-PER: 375 (target: 350, diff: 25)\n",
      "\n",
      "Final tag frequencies:\n",
      "B-LOC: 479 (target: 350, diff: 129)\n",
      "B-MISC: 385 (target: 350, diff: 35)\n",
      "B-ORG: 445 (target: 350, diff: 95)\n",
      "B-PER: 385 (target: 350, diff: 35)\n",
      "I-LOC: 345 (target: 350, diff: -5)\n",
      "I-MISC: 530 (target: 350, diff: 180)\n",
      "I-ORG: 376 (target: 350, diff: 26)\n",
      "I-PER: 375 (target: 350, diff: 25)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    target_frequencies = {\n",
    "        'B-ORG': 350,\n",
    "        'I-ORG': 350,\n",
    "        'B-PER': 350,\n",
    "        'I-PER': 350,\n",
    "        'B-LOC': 350,\n",
    "        'I-LOC': 350,\n",
    "        'B-MISC': 350,\n",
    "        'I-MISC': 350\n",
    "    }\n",
    "    \n",
    "    balancer = NERBalancer(target_frequencies)\n",
    "    balancer.process_file(r'c:\\Users\\Sakib Ahmed\\Desktop\\CoNLL2002_Cleaned++.conll', 'balanced_output_hardcore.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
